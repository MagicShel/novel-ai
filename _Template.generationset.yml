# Randomness
# Higher values make the AI more daring by selecting less likely outcomes.
# Can lead to nonsense of set too high.
# Slider Range: 0.1 - 2.5 (default: 0.55)
temperature: 0.65

# Max Output Length (tokens)
max_length: 60

# Min Output Length (tokens)
min_length: 20

# Top-K Sampling
# Increases consistency by only selecting the most likely tokens and
# redistributing the probabilities. Lower settings create a smaller pool
# of tokens, trading creativity for consistency.
# Slider Range: 0-150 (default: 140)
# 0 disables
# NOTE: Not intended for use with Tail-Free sampling
top_k: 0

# Nucleus Sampling
# Increases consistency by taking tokens from the top and adding up
# their probabilities until it reaches the percentage set. Lower settings
# create a smaller pool of tokens, trading creativity for consistency.
# Slider Range: 0.05 - 0.975 (default: 0.9)
# 1 disables
# NOTE: Not intended for use with Tail-Free sampling
top_p: 1

# Tail-Free Sampling
# Increases the consistency of the output by working from the bottom and
# trimming the 'worst' possible tokens. Generally has a smaller effect
# on creativity than other sampling types.
# Slider Range: 0.05 - 0.999 (default: disabled)
# 0 disables
# NOTE: Not intended for use with Top-K or Nucleus sampling
tail_free_sampling: 0.8

# Repetition Penalty
# Reduces the chances of a word appearing multiple times in the output.
# Can help reduce repetitive sentences. Due to model-specific behavior,
# when using GPT-J 6B this value is scaled linearly to a value between
# 1 and 1.525
# Slider Range: 1-8 (default: 3.5)
repetition_penalty: 2.8

# Repetition Penalty Range
# How many tokens, starting from the last generated one, will be
# considered repeated if they appear in the next output.
# Slider Range: 0 - 2048 (default: 1024)
# 0 disables
repetition_penalty_range: 512

# Repetition Penalty Slope
# Affects the ramping of the penalty's harshness, starting from the final
# token. Higher values penalize the final tokens more harshly, but are
# softer on the earlier tokens. Lower values cause a smoother reduction
# of probablily across all tokens.
# Slider Range: 0 - 9.99 (default: 6.57)
repetition_penalty_slope: 3.33

# Banned Token Sequences
# Prevents certain token sequences from being generated. Similar
# sequences (different capitalization, extra spaces) will be banned as
# well. Tokens can also be entered by ID: [123] or [123,124,125] for
# sequences. To prevent banning similar sequences, surround with
# brackets: [help] or {help}
bad_words_ids: []
